{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0edee81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"I woke up early and made myself a cup of coffee\",\n",
    "    \"The sun was shining through the curtains this morning\",\n",
    "    \"I took a short walk before starting my work\",\n",
    "    \"My phone buzzed with a message from an old friend\",\n",
    "    \"Breakfast tasted better than usual today\",\n",
    "    \"I watered the plants and watched the leaves shimmer in the light\",\n",
    "    \"There was a gentle breeze outside my window\",\n",
    "    \"I turned on some music to make the morning feel lighter\",\n",
    "    \"The cat jumped on the table looking for attention\",\n",
    "    \"I checked my emails before the day got too busy\",\n",
    "    \"Lunch was simple but surprisingly delicious\",\n",
    "    \"I tried a new recipe I found online last night\",\n",
    "    \"After lunch I sat down with a cup of tea and a book\",\n",
    "    \"The story pulled me in until I lost track of time\",\n",
    "    \"I went out to buy groceries and bumped into a neighbor\",\n",
    "    \"The supermarket was quieter than usual today\",\n",
    "    \"I picked up some fresh fruit and a loaf of bread\",\n",
    "    \"The cashier smiled and wished me a nice evening\",\n",
    "    \"When I got home it started to rain softly\",\n",
    "    \"I opened the window and listened to the sound of the rain\",\n",
    "    \"Dinner was warm and comforting after a long day\",\n",
    "    \"I cleaned the kitchen while humming a familiar tune\",\n",
    "    \"Before bed I wrote a few lines in my journal\",\n",
    "    \"I thought about how fast the week had gone by\",\n",
    "    \"The moonlight filled my room through the open curtains\",\n",
    "    \"I scrolled through social media for a few minutes before sleeping\",\n",
    "    \"Dreams came and went without making much sense\",\n",
    "    \"I woke up again to the sound of birds outside\",\n",
    "    \"The smell of fresh coffee made me smile\",\n",
    "    \"I decided to start my day with some stretching\",\n",
    "    \"The floor felt cold beneath my feet as I moved around\",\n",
    "    \"I checked the news but quickly got bored of it\",\n",
    "    \"A friend called to share some exciting news\",\n",
    "    \"I congratulated her and promised to meet soon\",\n",
    "    \"Lunch today was leftovers from last night’s dinner\",\n",
    "    \"I worked on a small project that had been pending for days\",\n",
    "    \"The internet connection was slower than usual\",\n",
    "    \"I made a playlist of songs I hadn’t heard in years\",\n",
    "    \"The evening sky turned shades of orange and pink\",\n",
    "    \"I took a few pictures to capture the moment\",\n",
    "    \"Dinner was quick because I didn’t feel like cooking much\",\n",
    "    \"I watched a short movie before going to bed\",\n",
    "    \"My dreams were filled with strange but happy scenes\",\n",
    "    \"The alarm went off but I hit snooze twice\",\n",
    "    \"I finally got up when the room was already bright\",\n",
    "    \"I checked my schedule for the day and sighed\",\n",
    "    \"There were too many meetings but not enough motivation\",\n",
    "    \"I brewed another cup of coffee and pushed myself to start\",\n",
    "    \"The first meeting went better than I expected\",\n",
    "    \"Someone made a joke that lightened the whole mood\",\n",
    "    \"By afternoon I was craving a nap\",\n",
    "    \"I stepped out for a walk to get some fresh air\",\n",
    "    \"The air smelled of rain even though the sky was clear\",\n",
    "    \"I met a dog that wagged its tail and followed me for a bit\",\n",
    "    \"I smiled and wished the owner a good day\",\n",
    "    \"When I got back I checked my phone again\",\n",
    "    \"There was a message reminding me of an upcoming event\",\n",
    "    \"I almost forgot that tomorrow was the weekend\",\n",
    "    \"The thought of sleeping in made me happy\",\n",
    "    \"Dinner was pasta with a bit too much cheese\",\n",
    "    \"I didn’t mind because it still tasted amazing\",\n",
    "    \"I sat by the window watching cars pass by\",\n",
    "    \"The streetlights reflected softly on the wet road\",\n",
    "    \"A song played in the background that reminded me of school days\",\n",
    "    \"I thought about how much life had changed since then\",\n",
    "    \"The clock struck eleven and I decided to call it a day\",\n",
    "    \"Morning came with the sound of thunder in the distance\",\n",
    "    \"The rain poured down but it felt oddly peaceful\",\n",
    "    \"I made pancakes and watched a movie while eating\",\n",
    "    \"The smell of vanilla filled the room\",\n",
    "    \"After breakfast I cleaned my workspace and organized my notes\",\n",
    "    \"I found an old sketchbook full of random doodles\",\n",
    "    \"It made me want to start drawing again\",\n",
    "    \"I spent the afternoon trying to sketch something simple\",\n",
    "    \"The result wasn’t great but it made me feel calm\",\n",
    "    \"Later I made a cup of hot chocolate and sat on the balcony\",\n",
    "    \"The city looked quiet under the evening clouds\",\n",
    "    \"I sent a few texts to friends asking how they were doing\",\n",
    "    \"We planned to meet next week if everyone was free\",\n",
    "    \"I cooked dinner while listening to a podcast about travel\",\n",
    "    \"The host talked about exploring small towns and hidden trails\",\n",
    "    \"I imagined walking through those peaceful streets someday\",\n",
    "    \"The night was cool and perfect for a short stroll\",\n",
    "    \"I locked the door and went out for a ten minute walk\",\n",
    "    \"The neighborhood dogs barked as I passed by\",\n",
    "    \"I waved at a kid riding his bicycle in circles\",\n",
    "    \"Back home I poured myself a glass of water and sat quietly\",\n",
    "    \"I scrolled through my photos and smiled at old memories\",\n",
    "    \"The smell of rain still lingered in the air\",\n",
    "    \"I turned off the lights and watched the ceiling fan spin\",\n",
    "    \"It felt good to end the day without rushing anything\",\n",
    "    \"Sleep came slowly but peacefully this time\",\n",
    "    \"Morning light touched the walls and woke me up gently\",\n",
    "    \"I stretched and took a deep breath before getting out of bed\",\n",
    "    \"The world outside felt calm and full of promise\",\n",
    "    \"I made my coffee and thought about what to do next\",\n",
    "    \"Maybe today would bring something unexpected and nice\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48d8fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a02b8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eba5d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aaa9a972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'a': 3,\n",
       " 'and': 4,\n",
       " 'of': 5,\n",
       " 'to': 6,\n",
       " 'was': 7,\n",
       " 'my': 8,\n",
       " 'made': 9,\n",
       " 'me': 10,\n",
       " 'in': 11,\n",
       " 'for': 12,\n",
       " 'but': 13,\n",
       " 'it': 14,\n",
       " 'day': 15,\n",
       " 'before': 16,\n",
       " 'with': 17,\n",
       " 'up': 18,\n",
       " 'through': 19,\n",
       " 'on': 20,\n",
       " 'some': 21,\n",
       " 'got': 22,\n",
       " 'went': 23,\n",
       " 'rain': 24,\n",
       " 'dinner': 25,\n",
       " 'about': 26,\n",
       " 'by': 27,\n",
       " 'that': 28,\n",
       " 'cup': 29,\n",
       " 'coffee': 30,\n",
       " 'morning': 31,\n",
       " 'than': 32,\n",
       " 'today': 33,\n",
       " 'watched': 34,\n",
       " 'checked': 35,\n",
       " 'sat': 36,\n",
       " 'out': 37,\n",
       " 'few': 38,\n",
       " 'thought': 39,\n",
       " 'much': 40,\n",
       " 'felt': 41,\n",
       " 'woke': 42,\n",
       " 'myself': 43,\n",
       " 'took': 44,\n",
       " 'short': 45,\n",
       " 'walk': 46,\n",
       " 'an': 47,\n",
       " 'old': 48,\n",
       " 'usual': 49,\n",
       " 'there': 50,\n",
       " 'outside': 51,\n",
       " 'window': 52,\n",
       " 'turned': 53,\n",
       " 'feel': 54,\n",
       " 'too': 55,\n",
       " 'lunch': 56,\n",
       " 'after': 57,\n",
       " 'fresh': 58,\n",
       " 'smiled': 59,\n",
       " 'evening': 60,\n",
       " 'when': 61,\n",
       " 'sound': 62,\n",
       " 'while': 63,\n",
       " 'bed': 64,\n",
       " 'how': 65,\n",
       " 'had': 66,\n",
       " 'filled': 67,\n",
       " 'room': 68,\n",
       " 'came': 69,\n",
       " 'again': 70,\n",
       " 'smell': 71,\n",
       " 'start': 72,\n",
       " 'were': 73,\n",
       " 'air': 74,\n",
       " 'curtains': 75,\n",
       " 'this': 76,\n",
       " 'phone': 77,\n",
       " 'message': 78,\n",
       " 'from': 79,\n",
       " 'friend': 80,\n",
       " 'breakfast': 81,\n",
       " 'tasted': 82,\n",
       " 'better': 83,\n",
       " 'light': 84,\n",
       " 'simple': 85,\n",
       " 'found': 86,\n",
       " 'last': 87,\n",
       " 'night': 88,\n",
       " 'down': 89,\n",
       " 'time': 90,\n",
       " 'wished': 91,\n",
       " 'nice': 92,\n",
       " 'home': 93,\n",
       " 'softly': 94,\n",
       " 'cleaned': 95,\n",
       " 'week': 96,\n",
       " 'scrolled': 97,\n",
       " 'sleeping': 98,\n",
       " 'dreams': 99,\n",
       " 'without': 100,\n",
       " 'decided': 101,\n",
       " 'as': 102,\n",
       " 'news': 103,\n",
       " 'meet': 104,\n",
       " 'small': 105,\n",
       " 'days': 106,\n",
       " 'sky': 107,\n",
       " 'because': 108,\n",
       " 'didn’t': 109,\n",
       " 'movie': 110,\n",
       " 'happy': 111,\n",
       " 'off': 112,\n",
       " 'afternoon': 113,\n",
       " 'bit': 114,\n",
       " 'good': 115,\n",
       " 'back': 116,\n",
       " 'still': 117,\n",
       " 'poured': 118,\n",
       " 'peaceful': 119,\n",
       " 'full': 120,\n",
       " 'something': 121,\n",
       " 'calm': 122,\n",
       " 'next': 123,\n",
       " 'at': 124,\n",
       " 'early': 125,\n",
       " 'sun': 126,\n",
       " 'shining': 127,\n",
       " 'starting': 128,\n",
       " 'work': 129,\n",
       " 'buzzed': 130,\n",
       " 'watered': 131,\n",
       " 'plants': 132,\n",
       " 'leaves': 133,\n",
       " 'shimmer': 134,\n",
       " 'gentle': 135,\n",
       " 'breeze': 136,\n",
       " 'music': 137,\n",
       " 'make': 138,\n",
       " 'lighter': 139,\n",
       " 'cat': 140,\n",
       " 'jumped': 141,\n",
       " 'table': 142,\n",
       " 'looking': 143,\n",
       " 'attention': 144,\n",
       " 'emails': 145,\n",
       " 'busy': 146,\n",
       " 'surprisingly': 147,\n",
       " 'delicious': 148,\n",
       " 'tried': 149,\n",
       " 'new': 150,\n",
       " 'recipe': 151,\n",
       " 'online': 152,\n",
       " 'tea': 153,\n",
       " 'book': 154,\n",
       " 'story': 155,\n",
       " 'pulled': 156,\n",
       " 'until': 157,\n",
       " 'lost': 158,\n",
       " 'track': 159,\n",
       " 'buy': 160,\n",
       " 'groceries': 161,\n",
       " 'bumped': 162,\n",
       " 'into': 163,\n",
       " 'neighbor': 164,\n",
       " 'supermarket': 165,\n",
       " 'quieter': 166,\n",
       " 'picked': 167,\n",
       " 'fruit': 168,\n",
       " 'loaf': 169,\n",
       " 'bread': 170,\n",
       " 'cashier': 171,\n",
       " 'started': 172,\n",
       " 'opened': 173,\n",
       " 'listened': 174,\n",
       " 'warm': 175,\n",
       " 'comforting': 176,\n",
       " 'long': 177,\n",
       " 'kitchen': 178,\n",
       " 'humming': 179,\n",
       " 'familiar': 180,\n",
       " 'tune': 181,\n",
       " 'wrote': 182,\n",
       " 'lines': 183,\n",
       " 'journal': 184,\n",
       " 'fast': 185,\n",
       " 'gone': 186,\n",
       " 'moonlight': 187,\n",
       " 'open': 188,\n",
       " 'social': 189,\n",
       " 'media': 190,\n",
       " 'minutes': 191,\n",
       " 'making': 192,\n",
       " 'sense': 193,\n",
       " 'birds': 194,\n",
       " 'smile': 195,\n",
       " 'stretching': 196,\n",
       " 'floor': 197,\n",
       " 'cold': 198,\n",
       " 'beneath': 199,\n",
       " 'feet': 200,\n",
       " 'moved': 201,\n",
       " 'around': 202,\n",
       " 'quickly': 203,\n",
       " 'bored': 204,\n",
       " 'called': 205,\n",
       " 'share': 206,\n",
       " 'exciting': 207,\n",
       " 'congratulated': 208,\n",
       " 'her': 209,\n",
       " 'promised': 210,\n",
       " 'soon': 211,\n",
       " 'leftovers': 212,\n",
       " 'night’s': 213,\n",
       " 'worked': 214,\n",
       " 'project': 215,\n",
       " 'been': 216,\n",
       " 'pending': 217,\n",
       " 'internet': 218,\n",
       " 'connection': 219,\n",
       " 'slower': 220,\n",
       " 'playlist': 221,\n",
       " 'songs': 222,\n",
       " 'hadn’t': 223,\n",
       " 'heard': 224,\n",
       " 'years': 225,\n",
       " 'shades': 226,\n",
       " 'orange': 227,\n",
       " 'pink': 228,\n",
       " 'pictures': 229,\n",
       " 'capture': 230,\n",
       " 'moment': 231,\n",
       " 'quick': 232,\n",
       " 'like': 233,\n",
       " 'cooking': 234,\n",
       " 'going': 235,\n",
       " 'strange': 236,\n",
       " 'scenes': 237,\n",
       " 'alarm': 238,\n",
       " 'hit': 239,\n",
       " 'snooze': 240,\n",
       " 'twice': 241,\n",
       " 'finally': 242,\n",
       " 'already': 243,\n",
       " 'bright': 244,\n",
       " 'schedule': 245,\n",
       " 'sighed': 246,\n",
       " 'many': 247,\n",
       " 'meetings': 248,\n",
       " 'not': 249,\n",
       " 'enough': 250,\n",
       " 'motivation': 251,\n",
       " 'brewed': 252,\n",
       " 'another': 253,\n",
       " 'pushed': 254,\n",
       " 'first': 255,\n",
       " 'meeting': 256,\n",
       " 'expected': 257,\n",
       " 'someone': 258,\n",
       " 'joke': 259,\n",
       " 'lightened': 260,\n",
       " 'whole': 261,\n",
       " 'mood': 262,\n",
       " 'craving': 263,\n",
       " 'nap': 264,\n",
       " 'stepped': 265,\n",
       " 'get': 266,\n",
       " 'smelled': 267,\n",
       " 'even': 268,\n",
       " 'though': 269,\n",
       " 'clear': 270,\n",
       " 'met': 271,\n",
       " 'dog': 272,\n",
       " 'wagged': 273,\n",
       " 'its': 274,\n",
       " 'tail': 275,\n",
       " 'followed': 276,\n",
       " 'owner': 277,\n",
       " 'reminding': 278,\n",
       " 'upcoming': 279,\n",
       " 'event': 280,\n",
       " 'almost': 281,\n",
       " 'forgot': 282,\n",
       " 'tomorrow': 283,\n",
       " 'weekend': 284,\n",
       " 'pasta': 285,\n",
       " 'cheese': 286,\n",
       " 'mind': 287,\n",
       " 'amazing': 288,\n",
       " 'watching': 289,\n",
       " 'cars': 290,\n",
       " 'pass': 291,\n",
       " 'streetlights': 292,\n",
       " 'reflected': 293,\n",
       " 'wet': 294,\n",
       " 'road': 295,\n",
       " 'song': 296,\n",
       " 'played': 297,\n",
       " 'background': 298,\n",
       " 'reminded': 299,\n",
       " 'school': 300,\n",
       " 'life': 301,\n",
       " 'changed': 302,\n",
       " 'since': 303,\n",
       " 'then': 304,\n",
       " 'clock': 305,\n",
       " 'struck': 306,\n",
       " 'eleven': 307,\n",
       " 'call': 308,\n",
       " 'thunder': 309,\n",
       " 'distance': 310,\n",
       " 'oddly': 311,\n",
       " 'pancakes': 312,\n",
       " 'eating': 313,\n",
       " 'vanilla': 314,\n",
       " 'workspace': 315,\n",
       " 'organized': 316,\n",
       " 'notes': 317,\n",
       " 'sketchbook': 318,\n",
       " 'random': 319,\n",
       " 'doodles': 320,\n",
       " 'want': 321,\n",
       " 'drawing': 322,\n",
       " 'spent': 323,\n",
       " 'trying': 324,\n",
       " 'sketch': 325,\n",
       " 'result': 326,\n",
       " 'wasn’t': 327,\n",
       " 'great': 328,\n",
       " 'later': 329,\n",
       " 'hot': 330,\n",
       " 'chocolate': 331,\n",
       " 'balcony': 332,\n",
       " 'city': 333,\n",
       " 'looked': 334,\n",
       " 'quiet': 335,\n",
       " 'under': 336,\n",
       " 'clouds': 337,\n",
       " 'sent': 338,\n",
       " 'texts': 339,\n",
       " 'friends': 340,\n",
       " 'asking': 341,\n",
       " 'they': 342,\n",
       " 'doing': 343,\n",
       " 'we': 344,\n",
       " 'planned': 345,\n",
       " 'if': 346,\n",
       " 'everyone': 347,\n",
       " 'free': 348,\n",
       " 'cooked': 349,\n",
       " 'listening': 350,\n",
       " 'podcast': 351,\n",
       " 'travel': 352,\n",
       " 'host': 353,\n",
       " 'talked': 354,\n",
       " 'exploring': 355,\n",
       " 'towns': 356,\n",
       " 'hidden': 357,\n",
       " 'trails': 358,\n",
       " 'imagined': 359,\n",
       " 'walking': 360,\n",
       " 'those': 361,\n",
       " 'streets': 362,\n",
       " 'someday': 363,\n",
       " 'cool': 364,\n",
       " 'perfect': 365,\n",
       " 'stroll': 366,\n",
       " 'locked': 367,\n",
       " 'door': 368,\n",
       " 'ten': 369,\n",
       " 'minute': 370,\n",
       " 'neighborhood': 371,\n",
       " 'dogs': 372,\n",
       " 'barked': 373,\n",
       " 'passed': 374,\n",
       " 'waved': 375,\n",
       " 'kid': 376,\n",
       " 'riding': 377,\n",
       " 'his': 378,\n",
       " 'bicycle': 379,\n",
       " 'circles': 380,\n",
       " 'glass': 381,\n",
       " 'water': 382,\n",
       " 'quietly': 383,\n",
       " 'photos': 384,\n",
       " 'memories': 385,\n",
       " 'lingered': 386,\n",
       " 'lights': 387,\n",
       " 'ceiling': 388,\n",
       " 'fan': 389,\n",
       " 'spin': 390,\n",
       " 'end': 391,\n",
       " 'rushing': 392,\n",
       " 'anything': 393,\n",
       " 'sleep': 394,\n",
       " 'slowly': 395,\n",
       " 'peacefully': 396,\n",
       " 'touched': 397,\n",
       " 'walls': 398,\n",
       " 'gently': 399,\n",
       " 'stretched': 400,\n",
       " 'deep': 401,\n",
       " 'breath': 402,\n",
       " 'getting': 403,\n",
       " 'world': 404,\n",
       " 'promise': 405,\n",
       " 'what': 406,\n",
       " 'do': 407,\n",
       " 'maybe': 408,\n",
       " 'would': 409,\n",
       " 'bring': 410,\n",
       " 'unexpected': 411}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b870788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the input-output dataset for next-word prediction\n",
    "# For example, given a tokenized sequence: [56, 7, 85, 13, 147, 148]\n",
    "# We create multiple input-output pairs like this:\n",
    "# Input | Output\n",
    "# [56] | 7\n",
    "# [56, 7] | 85\n",
    "# [56, 7, 85] | 13\n",
    "# [56, 7, 85, 13] | 147\n",
    "# [56, 7, 85, 13, 147] | 148\n",
    "# Each input sequence helps the LSTM learn to predict the next word in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "67b6acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "'''[sentence] ensures the tokenizer sees it as a single text.\n",
    "\n",
    "[0] extracts the actual sequence from the returned list.'''\n",
    "for sentence in dataset:\n",
    "    tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0] # converts sentences into vectors\n",
    "\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed5ecee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 42],\n",
       " [2, 42, 18],\n",
       " [2, 42, 18, 125],\n",
       " [2, 42, 18, 125, 4],\n",
       " [2, 42, 18, 125, 4, 9],\n",
       " [2, 42, 18, 125, 4, 9, 43],\n",
       " [2, 42, 18, 125, 4, 9, 43, 3],\n",
       " [2, 42, 18, 125, 4, 9, 43, 3, 29],\n",
       " [2, 42, 18, 125, 4, 9, 43, 3, 29, 5],\n",
       " [2, 42, 18, 125, 4, 9, 43, 3, 29, 5, 30],\n",
       " [1, 126],\n",
       " [1, 126, 7],\n",
       " [1, 126, 7, 127],\n",
       " [1, 126, 7, 127, 19],\n",
       " [1, 126, 7, 127, 19, 1],\n",
       " [1, 126, 7, 127, 19, 1, 75],\n",
       " [1, 126, 7, 127, 19, 1, 75, 76],\n",
       " [1, 126, 7, 127, 19, 1, 75, 76, 31],\n",
       " [2, 44],\n",
       " [2, 44, 3],\n",
       " [2, 44, 3, 45],\n",
       " [2, 44, 3, 45, 46],\n",
       " [2, 44, 3, 45, 46, 16],\n",
       " [2, 44, 3, 45, 46, 16, 128],\n",
       " [2, 44, 3, 45, 46, 16, 128, 8],\n",
       " [2, 44, 3, 45, 46, 16, 128, 8, 129],\n",
       " [8, 77],\n",
       " [8, 77, 130],\n",
       " [8, 77, 130, 17],\n",
       " [8, 77, 130, 17, 3],\n",
       " [8, 77, 130, 17, 3, 78],\n",
       " [8, 77, 130, 17, 3, 78, 79],\n",
       " [8, 77, 130, 17, 3, 78, 79, 47],\n",
       " [8, 77, 130, 17, 3, 78, 79, 47, 48],\n",
       " [8, 77, 130, 17, 3, 78, 79, 47, 48, 80],\n",
       " [81, 82],\n",
       " [81, 82, 83],\n",
       " [81, 82, 83, 32],\n",
       " [81, 82, 83, 32, 49],\n",
       " [81, 82, 83, 32, 49, 33],\n",
       " [2, 131],\n",
       " [2, 131, 1],\n",
       " [2, 131, 1, 132],\n",
       " [2, 131, 1, 132, 4],\n",
       " [2, 131, 1, 132, 4, 34],\n",
       " [2, 131, 1, 132, 4, 34, 1],\n",
       " [2, 131, 1, 132, 4, 34, 1, 133],\n",
       " [2, 131, 1, 132, 4, 34, 1, 133, 134],\n",
       " [2, 131, 1, 132, 4, 34, 1, 133, 134, 11],\n",
       " [2, 131, 1, 132, 4, 34, 1, 133, 134, 11, 1],\n",
       " [2, 131, 1, 132, 4, 34, 1, 133, 134, 11, 1, 84],\n",
       " [50, 7],\n",
       " [50, 7, 3],\n",
       " [50, 7, 3, 135],\n",
       " [50, 7, 3, 135, 136],\n",
       " [50, 7, 3, 135, 136, 51],\n",
       " [50, 7, 3, 135, 136, 51, 8],\n",
       " [50, 7, 3, 135, 136, 51, 8, 52],\n",
       " [2, 53],\n",
       " [2, 53, 20],\n",
       " [2, 53, 20, 21],\n",
       " [2, 53, 20, 21, 137],\n",
       " [2, 53, 20, 21, 137, 6],\n",
       " [2, 53, 20, 21, 137, 6, 138],\n",
       " [2, 53, 20, 21, 137, 6, 138, 1],\n",
       " [2, 53, 20, 21, 137, 6, 138, 1, 31],\n",
       " [2, 53, 20, 21, 137, 6, 138, 1, 31, 54],\n",
       " [2, 53, 20, 21, 137, 6, 138, 1, 31, 54, 139],\n",
       " [1, 140],\n",
       " [1, 140, 141],\n",
       " [1, 140, 141, 20],\n",
       " [1, 140, 141, 20, 1],\n",
       " [1, 140, 141, 20, 1, 142],\n",
       " [1, 140, 141, 20, 1, 142, 143],\n",
       " [1, 140, 141, 20, 1, 142, 143, 12],\n",
       " [1, 140, 141, 20, 1, 142, 143, 12, 144],\n",
       " [2, 35],\n",
       " [2, 35, 8],\n",
       " [2, 35, 8, 145],\n",
       " [2, 35, 8, 145, 16],\n",
       " [2, 35, 8, 145, 16, 1],\n",
       " [2, 35, 8, 145, 16, 1, 15],\n",
       " [2, 35, 8, 145, 16, 1, 15, 22],\n",
       " [2, 35, 8, 145, 16, 1, 15, 22, 55],\n",
       " [2, 35, 8, 145, 16, 1, 15, 22, 55, 146],\n",
       " [56, 7],\n",
       " [56, 7, 85],\n",
       " [56, 7, 85, 13],\n",
       " [56, 7, 85, 13, 147],\n",
       " [56, 7, 85, 13, 147, 148],\n",
       " [2, 149],\n",
       " [2, 149, 3],\n",
       " [2, 149, 3, 150],\n",
       " [2, 149, 3, 150, 151],\n",
       " [2, 149, 3, 150, 151, 2],\n",
       " [2, 149, 3, 150, 151, 2, 86],\n",
       " [2, 149, 3, 150, 151, 2, 86, 152],\n",
       " [2, 149, 3, 150, 151, 2, 86, 152, 87],\n",
       " [2, 149, 3, 150, 151, 2, 86, 152, 87, 88],\n",
       " [57, 56],\n",
       " [57, 56, 2],\n",
       " [57, 56, 2, 36],\n",
       " [57, 56, 2, 36, 89],\n",
       " [57, 56, 2, 36, 89, 17],\n",
       " [57, 56, 2, 36, 89, 17, 3],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29, 5],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29, 5, 153],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29, 5, 153, 4],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29, 5, 153, 4, 3],\n",
       " [57, 56, 2, 36, 89, 17, 3, 29, 5, 153, 4, 3, 154],\n",
       " [1, 155],\n",
       " [1, 155, 156],\n",
       " [1, 155, 156, 10],\n",
       " [1, 155, 156, 10, 11],\n",
       " [1, 155, 156, 10, 11, 157],\n",
       " [1, 155, 156, 10, 11, 157, 2],\n",
       " [1, 155, 156, 10, 11, 157, 2, 158],\n",
       " [1, 155, 156, 10, 11, 157, 2, 158, 159],\n",
       " [1, 155, 156, 10, 11, 157, 2, 158, 159, 5],\n",
       " [1, 155, 156, 10, 11, 157, 2, 158, 159, 5, 90],\n",
       " [2, 23],\n",
       " [2, 23, 37],\n",
       " [2, 23, 37, 6],\n",
       " [2, 23, 37, 6, 160],\n",
       " [2, 23, 37, 6, 160, 161],\n",
       " [2, 23, 37, 6, 160, 161, 4],\n",
       " [2, 23, 37, 6, 160, 161, 4, 162],\n",
       " [2, 23, 37, 6, 160, 161, 4, 162, 163],\n",
       " [2, 23, 37, 6, 160, 161, 4, 162, 163, 3],\n",
       " [2, 23, 37, 6, 160, 161, 4, 162, 163, 3, 164],\n",
       " [1, 165],\n",
       " [1, 165, 7],\n",
       " [1, 165, 7, 166],\n",
       " [1, 165, 7, 166, 32],\n",
       " [1, 165, 7, 166, 32, 49],\n",
       " [1, 165, 7, 166, 32, 49, 33],\n",
       " [2, 167],\n",
       " [2, 167, 18],\n",
       " [2, 167, 18, 21],\n",
       " [2, 167, 18, 21, 58],\n",
       " [2, 167, 18, 21, 58, 168],\n",
       " [2, 167, 18, 21, 58, 168, 4],\n",
       " [2, 167, 18, 21, 58, 168, 4, 3],\n",
       " [2, 167, 18, 21, 58, 168, 4, 3, 169],\n",
       " [2, 167, 18, 21, 58, 168, 4, 3, 169, 5],\n",
       " [2, 167, 18, 21, 58, 168, 4, 3, 169, 5, 170],\n",
       " [1, 171],\n",
       " [1, 171, 59],\n",
       " [1, 171, 59, 4],\n",
       " [1, 171, 59, 4, 91],\n",
       " [1, 171, 59, 4, 91, 10],\n",
       " [1, 171, 59, 4, 91, 10, 3],\n",
       " [1, 171, 59, 4, 91, 10, 3, 92],\n",
       " [1, 171, 59, 4, 91, 10, 3, 92, 60],\n",
       " [61, 2],\n",
       " [61, 2, 22],\n",
       " [61, 2, 22, 93],\n",
       " [61, 2, 22, 93, 14],\n",
       " [61, 2, 22, 93, 14, 172],\n",
       " [61, 2, 22, 93, 14, 172, 6],\n",
       " [61, 2, 22, 93, 14, 172, 6, 24],\n",
       " [61, 2, 22, 93, 14, 172, 6, 24, 94],\n",
       " [2, 173],\n",
       " [2, 173, 1],\n",
       " [2, 173, 1, 52],\n",
       " [2, 173, 1, 52, 4],\n",
       " [2, 173, 1, 52, 4, 174],\n",
       " [2, 173, 1, 52, 4, 174, 6],\n",
       " [2, 173, 1, 52, 4, 174, 6, 1],\n",
       " [2, 173, 1, 52, 4, 174, 6, 1, 62],\n",
       " [2, 173, 1, 52, 4, 174, 6, 1, 62, 5],\n",
       " [2, 173, 1, 52, 4, 174, 6, 1, 62, 5, 1],\n",
       " [2, 173, 1, 52, 4, 174, 6, 1, 62, 5, 1, 24],\n",
       " [25, 7],\n",
       " [25, 7, 175],\n",
       " [25, 7, 175, 4],\n",
       " [25, 7, 175, 4, 176],\n",
       " [25, 7, 175, 4, 176, 57],\n",
       " [25, 7, 175, 4, 176, 57, 3],\n",
       " [25, 7, 175, 4, 176, 57, 3, 177],\n",
       " [25, 7, 175, 4, 176, 57, 3, 177, 15],\n",
       " [2, 95],\n",
       " [2, 95, 1],\n",
       " [2, 95, 1, 178],\n",
       " [2, 95, 1, 178, 63],\n",
       " [2, 95, 1, 178, 63, 179],\n",
       " [2, 95, 1, 178, 63, 179, 3],\n",
       " [2, 95, 1, 178, 63, 179, 3, 180],\n",
       " [2, 95, 1, 178, 63, 179, 3, 180, 181],\n",
       " [16, 64],\n",
       " [16, 64, 2],\n",
       " [16, 64, 2, 182],\n",
       " [16, 64, 2, 182, 3],\n",
       " [16, 64, 2, 182, 3, 38],\n",
       " [16, 64, 2, 182, 3, 38, 183],\n",
       " [16, 64, 2, 182, 3, 38, 183, 11],\n",
       " [16, 64, 2, 182, 3, 38, 183, 11, 8],\n",
       " [16, 64, 2, 182, 3, 38, 183, 11, 8, 184],\n",
       " [2, 39],\n",
       " [2, 39, 26],\n",
       " [2, 39, 26, 65],\n",
       " [2, 39, 26, 65, 185],\n",
       " [2, 39, 26, 65, 185, 1],\n",
       " [2, 39, 26, 65, 185, 1, 96],\n",
       " [2, 39, 26, 65, 185, 1, 96, 66],\n",
       " [2, 39, 26, 65, 185, 1, 96, 66, 186],\n",
       " [2, 39, 26, 65, 185, 1, 96, 66, 186, 27],\n",
       " [1, 187],\n",
       " [1, 187, 67],\n",
       " [1, 187, 67, 8],\n",
       " [1, 187, 67, 8, 68],\n",
       " [1, 187, 67, 8, 68, 19],\n",
       " [1, 187, 67, 8, 68, 19, 1],\n",
       " [1, 187, 67, 8, 68, 19, 1, 188],\n",
       " [1, 187, 67, 8, 68, 19, 1, 188, 75],\n",
       " [2, 97],\n",
       " [2, 97, 19],\n",
       " [2, 97, 19, 189],\n",
       " [2, 97, 19, 189, 190],\n",
       " [2, 97, 19, 189, 190, 12],\n",
       " [2, 97, 19, 189, 190, 12, 3],\n",
       " [2, 97, 19, 189, 190, 12, 3, 38],\n",
       " [2, 97, 19, 189, 190, 12, 3, 38, 191],\n",
       " [2, 97, 19, 189, 190, 12, 3, 38, 191, 16],\n",
       " [2, 97, 19, 189, 190, 12, 3, 38, 191, 16, 98],\n",
       " [99, 69],\n",
       " [99, 69, 4],\n",
       " [99, 69, 4, 23],\n",
       " [99, 69, 4, 23, 100],\n",
       " [99, 69, 4, 23, 100, 192],\n",
       " [99, 69, 4, 23, 100, 192, 40],\n",
       " [99, 69, 4, 23, 100, 192, 40, 193],\n",
       " [2, 42],\n",
       " [2, 42, 18],\n",
       " [2, 42, 18, 70],\n",
       " [2, 42, 18, 70, 6],\n",
       " [2, 42, 18, 70, 6, 1],\n",
       " [2, 42, 18, 70, 6, 1, 62],\n",
       " [2, 42, 18, 70, 6, 1, 62, 5],\n",
       " [2, 42, 18, 70, 6, 1, 62, 5, 194],\n",
       " [2, 42, 18, 70, 6, 1, 62, 5, 194, 51],\n",
       " [1, 71],\n",
       " [1, 71, 5],\n",
       " [1, 71, 5, 58],\n",
       " [1, 71, 5, 58, 30],\n",
       " [1, 71, 5, 58, 30, 9],\n",
       " [1, 71, 5, 58, 30, 9, 10],\n",
       " [1, 71, 5, 58, 30, 9, 10, 195],\n",
       " [2, 101],\n",
       " [2, 101, 6],\n",
       " [2, 101, 6, 72],\n",
       " [2, 101, 6, 72, 8],\n",
       " [2, 101, 6, 72, 8, 15],\n",
       " [2, 101, 6, 72, 8, 15, 17],\n",
       " [2, 101, 6, 72, 8, 15, 17, 21],\n",
       " [2, 101, 6, 72, 8, 15, 17, 21, 196],\n",
       " [1, 197],\n",
       " [1, 197, 41],\n",
       " [1, 197, 41, 198],\n",
       " [1, 197, 41, 198, 199],\n",
       " [1, 197, 41, 198, 199, 8],\n",
       " [1, 197, 41, 198, 199, 8, 200],\n",
       " [1, 197, 41, 198, 199, 8, 200, 102],\n",
       " [1, 197, 41, 198, 199, 8, 200, 102, 2],\n",
       " [1, 197, 41, 198, 199, 8, 200, 102, 2, 201],\n",
       " [1, 197, 41, 198, 199, 8, 200, 102, 2, 201, 202],\n",
       " [2, 35],\n",
       " [2, 35, 1],\n",
       " [2, 35, 1, 103],\n",
       " [2, 35, 1, 103, 13],\n",
       " [2, 35, 1, 103, 13, 203],\n",
       " [2, 35, 1, 103, 13, 203, 22],\n",
       " [2, 35, 1, 103, 13, 203, 22, 204],\n",
       " [2, 35, 1, 103, 13, 203, 22, 204, 5],\n",
       " [2, 35, 1, 103, 13, 203, 22, 204, 5, 14],\n",
       " [3, 80],\n",
       " [3, 80, 205],\n",
       " [3, 80, 205, 6],\n",
       " [3, 80, 205, 6, 206],\n",
       " [3, 80, 205, 6, 206, 21],\n",
       " [3, 80, 205, 6, 206, 21, 207],\n",
       " [3, 80, 205, 6, 206, 21, 207, 103],\n",
       " [2, 208],\n",
       " [2, 208, 209],\n",
       " [2, 208, 209, 4],\n",
       " [2, 208, 209, 4, 210],\n",
       " [2, 208, 209, 4, 210, 6],\n",
       " [2, 208, 209, 4, 210, 6, 104],\n",
       " [2, 208, 209, 4, 210, 6, 104, 211],\n",
       " [56, 33],\n",
       " [56, 33, 7],\n",
       " [56, 33, 7, 212],\n",
       " [56, 33, 7, 212, 79],\n",
       " [56, 33, 7, 212, 79, 87],\n",
       " [56, 33, 7, 212, 79, 87, 213],\n",
       " [56, 33, 7, 212, 79, 87, 213, 25],\n",
       " [2, 214],\n",
       " [2, 214, 20],\n",
       " [2, 214, 20, 3],\n",
       " [2, 214, 20, 3, 105],\n",
       " [2, 214, 20, 3, 105, 215],\n",
       " [2, 214, 20, 3, 105, 215, 28],\n",
       " [2, 214, 20, 3, 105, 215, 28, 66],\n",
       " [2, 214, 20, 3, 105, 215, 28, 66, 216],\n",
       " [2, 214, 20, 3, 105, 215, 28, 66, 216, 217],\n",
       " [2, 214, 20, 3, 105, 215, 28, 66, 216, 217, 12],\n",
       " [2, 214, 20, 3, 105, 215, 28, 66, 216, 217, 12, 106],\n",
       " [1, 218],\n",
       " [1, 218, 219],\n",
       " [1, 218, 219, 7],\n",
       " [1, 218, 219, 7, 220],\n",
       " [1, 218, 219, 7, 220, 32],\n",
       " [1, 218, 219, 7, 220, 32, 49],\n",
       " [2, 9],\n",
       " [2, 9, 3],\n",
       " [2, 9, 3, 221],\n",
       " [2, 9, 3, 221, 5],\n",
       " [2, 9, 3, 221, 5, 222],\n",
       " [2, 9, 3, 221, 5, 222, 2],\n",
       " [2, 9, 3, 221, 5, 222, 2, 223],\n",
       " [2, 9, 3, 221, 5, 222, 2, 223, 224],\n",
       " [2, 9, 3, 221, 5, 222, 2, 223, 224, 11],\n",
       " [2, 9, 3, 221, 5, 222, 2, 223, 224, 11, 225],\n",
       " [1, 60],\n",
       " [1, 60, 107],\n",
       " [1, 60, 107, 53],\n",
       " [1, 60, 107, 53, 226],\n",
       " [1, 60, 107, 53, 226, 5],\n",
       " [1, 60, 107, 53, 226, 5, 227],\n",
       " [1, 60, 107, 53, 226, 5, 227, 4],\n",
       " [1, 60, 107, 53, 226, 5, 227, 4, 228],\n",
       " [2, 44],\n",
       " [2, 44, 3],\n",
       " [2, 44, 3, 38],\n",
       " [2, 44, 3, 38, 229],\n",
       " [2, 44, 3, 38, 229, 6],\n",
       " [2, 44, 3, 38, 229, 6, 230],\n",
       " [2, 44, 3, 38, 229, 6, 230, 1],\n",
       " [2, 44, 3, 38, 229, 6, 230, 1, 231],\n",
       " [25, 7],\n",
       " [25, 7, 232],\n",
       " [25, 7, 232, 108],\n",
       " [25, 7, 232, 108, 2],\n",
       " [25, 7, 232, 108, 2, 109],\n",
       " [25, 7, 232, 108, 2, 109, 54],\n",
       " [25, 7, 232, 108, 2, 109, 54, 233],\n",
       " [25, 7, 232, 108, 2, 109, 54, 233, 234],\n",
       " [25, 7, 232, 108, 2, 109, 54, 233, 234, 40],\n",
       " [2, 34],\n",
       " [2, 34, 3],\n",
       " [2, 34, 3, 45],\n",
       " [2, 34, 3, 45, 110],\n",
       " [2, 34, 3, 45, 110, 16],\n",
       " [2, 34, 3, 45, 110, 16, 235],\n",
       " [2, 34, 3, 45, 110, 16, 235, 6],\n",
       " [2, 34, 3, 45, 110, 16, 235, 6, 64],\n",
       " [8, 99],\n",
       " [8, 99, 73],\n",
       " [8, 99, 73, 67],\n",
       " [8, 99, 73, 67, 17],\n",
       " [8, 99, 73, 67, 17, 236],\n",
       " [8, 99, 73, 67, 17, 236, 13],\n",
       " [8, 99, 73, 67, 17, 236, 13, 111],\n",
       " [8, 99, 73, 67, 17, 236, 13, 111, 237],\n",
       " [1, 238],\n",
       " [1, 238, 23],\n",
       " [1, 238, 23, 112],\n",
       " [1, 238, 23, 112, 13],\n",
       " [1, 238, 23, 112, 13, 2],\n",
       " [1, 238, 23, 112, 13, 2, 239],\n",
       " [1, 238, 23, 112, 13, 2, 239, 240],\n",
       " [1, 238, 23, 112, 13, 2, 239, 240, 241],\n",
       " [2, 242],\n",
       " [2, 242, 22],\n",
       " [2, 242, 22, 18],\n",
       " [2, 242, 22, 18, 61],\n",
       " [2, 242, 22, 18, 61, 1],\n",
       " [2, 242, 22, 18, 61, 1, 68],\n",
       " [2, 242, 22, 18, 61, 1, 68, 7],\n",
       " [2, 242, 22, 18, 61, 1, 68, 7, 243],\n",
       " [2, 242, 22, 18, 61, 1, 68, 7, 243, 244],\n",
       " [2, 35],\n",
       " [2, 35, 8],\n",
       " [2, 35, 8, 245],\n",
       " [2, 35, 8, 245, 12],\n",
       " [2, 35, 8, 245, 12, 1],\n",
       " [2, 35, 8, 245, 12, 1, 15],\n",
       " [2, 35, 8, 245, 12, 1, 15, 4],\n",
       " [2, 35, 8, 245, 12, 1, 15, 4, 246],\n",
       " [50, 73],\n",
       " [50, 73, 55],\n",
       " [50, 73, 55, 247],\n",
       " [50, 73, 55, 247, 248],\n",
       " [50, 73, 55, 247, 248, 13],\n",
       " [50, 73, 55, 247, 248, 13, 249],\n",
       " [50, 73, 55, 247, 248, 13, 249, 250],\n",
       " [50, 73, 55, 247, 248, 13, 249, 250, 251],\n",
       " [2, 252],\n",
       " [2, 252, 253],\n",
       " [2, 252, 253, 29],\n",
       " [2, 252, 253, 29, 5],\n",
       " [2, 252, 253, 29, 5, 30],\n",
       " [2, 252, 253, 29, 5, 30, 4],\n",
       " [2, 252, 253, 29, 5, 30, 4, 254],\n",
       " [2, 252, 253, 29, 5, 30, 4, 254, 43],\n",
       " [2, 252, 253, 29, 5, 30, 4, 254, 43, 6],\n",
       " [2, 252, 253, 29, 5, 30, 4, 254, 43, 6, 72],\n",
       " [1, 255],\n",
       " [1, 255, 256],\n",
       " [1, 255, 256, 23],\n",
       " [1, 255, 256, 23, 83],\n",
       " [1, 255, 256, 23, 83, 32],\n",
       " [1, 255, 256, 23, 83, 32, 2],\n",
       " [1, 255, 256, 23, 83, 32, 2, 257],\n",
       " [258, 9],\n",
       " [258, 9, 3],\n",
       " [258, 9, 3, 259],\n",
       " [258, 9, 3, 259, 28],\n",
       " [258, 9, 3, 259, 28, 260],\n",
       " [258, 9, 3, 259, 28, 260, 1],\n",
       " [258, 9, 3, 259, 28, 260, 1, 261],\n",
       " [258, 9, 3, 259, 28, 260, 1, 261, 262],\n",
       " [27, 113],\n",
       " [27, 113, 2],\n",
       " [27, 113, 2, 7],\n",
       " [27, 113, 2, 7, 263],\n",
       " [27, 113, 2, 7, 263, 3],\n",
       " [27, 113, 2, 7, 263, 3, 264],\n",
       " [2, 265],\n",
       " [2, 265, 37],\n",
       " [2, 265, 37, 12],\n",
       " [2, 265, 37, 12, 3],\n",
       " [2, 265, 37, 12, 3, 46],\n",
       " [2, 265, 37, 12, 3, 46, 6],\n",
       " [2, 265, 37, 12, 3, 46, 6, 266],\n",
       " [2, 265, 37, 12, 3, 46, 6, 266, 21],\n",
       " [2, 265, 37, 12, 3, 46, 6, 266, 21, 58],\n",
       " [2, 265, 37, 12, 3, 46, 6, 266, 21, 58, 74],\n",
       " [1, 74],\n",
       " [1, 74, 267],\n",
       " [1, 74, 267, 5],\n",
       " [1, 74, 267, 5, 24],\n",
       " [1, 74, 267, 5, 24, 268],\n",
       " [1, 74, 267, 5, 24, 268, 269],\n",
       " [1, 74, 267, 5, 24, 268, 269, 1],\n",
       " [1, 74, 267, 5, 24, 268, 269, 1, 107],\n",
       " [1, 74, 267, 5, 24, 268, 269, 1, 107, 7],\n",
       " [1, 74, 267, 5, 24, 268, 269, 1, 107, 7, 270],\n",
       " [2, 271],\n",
       " [2, 271, 3],\n",
       " [2, 271, 3, 272],\n",
       " [2, 271, 3, 272, 28],\n",
       " [2, 271, 3, 272, 28, 273],\n",
       " [2, 271, 3, 272, 28, 273, 274],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4, 276],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4, 276, 10],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4, 276, 10, 12],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4, 276, 10, 12, 3],\n",
       " [2, 271, 3, 272, 28, 273, 274, 275, 4, 276, 10, 12, 3, 114],\n",
       " [2, 59],\n",
       " [2, 59, 4],\n",
       " [2, 59, 4, 91],\n",
       " [2, 59, 4, 91, 1],\n",
       " [2, 59, 4, 91, 1, 277],\n",
       " [2, 59, 4, 91, 1, 277, 3],\n",
       " [2, 59, 4, 91, 1, 277, 3, 115],\n",
       " [2, 59, 4, 91, 1, 277, 3, 115, 15],\n",
       " [61, 2],\n",
       " [61, 2, 22],\n",
       " [61, 2, 22, 116],\n",
       " [61, 2, 22, 116, 2],\n",
       " [61, 2, 22, 116, 2, 35],\n",
       " [61, 2, 22, 116, 2, 35, 8],\n",
       " [61, 2, 22, 116, 2, 35, 8, 77],\n",
       " [61, 2, 22, 116, 2, 35, 8, 77, 70],\n",
       " [50, 7],\n",
       " [50, 7, 3],\n",
       " [50, 7, 3, 78],\n",
       " [50, 7, 3, 78, 278],\n",
       " [50, 7, 3, 78, 278, 10],\n",
       " [50, 7, 3, 78, 278, 10, 5],\n",
       " [50, 7, 3, 78, 278, 10, 5, 47],\n",
       " [50, 7, 3, 78, 278, 10, 5, 47, 279],\n",
       " [50, 7, 3, 78, 278, 10, 5, 47, 279, 280],\n",
       " [2, 281],\n",
       " [2, 281, 282],\n",
       " [2, 281, 282, 28],\n",
       " [2, 281, 282, 28, 283],\n",
       " [2, 281, 282, 28, 283, 7],\n",
       " [2, 281, 282, 28, 283, 7, 1],\n",
       " [2, 281, 282, 28, 283, 7, 1, 284],\n",
       " [1, 39],\n",
       " [1, 39, 5],\n",
       " [1, 39, 5, 98],\n",
       " [1, 39, 5, 98, 11],\n",
       " [1, 39, 5, 98, 11, 9],\n",
       " [1, 39, 5, 98, 11, 9, 10],\n",
       " [1, 39, 5, 98, 11, 9, 10, 111],\n",
       " [25, 7],\n",
       " [25, 7, 285],\n",
       " [25, 7, 285, 17],\n",
       " [25, 7, 285, 17, 3],\n",
       " [25, 7, 285, 17, 3, 114],\n",
       " [25, 7, 285, 17, 3, 114, 55],\n",
       " [25, 7, 285, 17, 3, 114, 55, 40],\n",
       " [25, 7, 285, 17, 3, 114, 55, 40, 286],\n",
       " [2, 109],\n",
       " [2, 109, 287],\n",
       " [2, 109, 287, 108],\n",
       " [2, 109, 287, 108, 14],\n",
       " [2, 109, 287, 108, 14, 117],\n",
       " [2, 109, 287, 108, 14, 117, 82],\n",
       " [2, 109, 287, 108, 14, 117, 82, 288],\n",
       " [2, 36],\n",
       " [2, 36, 27],\n",
       " [2, 36, 27, 1],\n",
       " [2, 36, 27, 1, 52],\n",
       " [2, 36, 27, 1, 52, 289],\n",
       " [2, 36, 27, 1, 52, 289, 290],\n",
       " [2, 36, 27, 1, 52, 289, 290, 291],\n",
       " [2, 36, 27, 1, 52, 289, 290, 291, 27],\n",
       " [1, 292],\n",
       " [1, 292, 293],\n",
       " [1, 292, 293, 94],\n",
       " [1, 292, 293, 94, 20],\n",
       " [1, 292, 293, 94, 20, 1],\n",
       " [1, 292, 293, 94, 20, 1, 294],\n",
       " [1, 292, 293, 94, 20, 1, 294, 295],\n",
       " [3, 296],\n",
       " [3, 296, 297],\n",
       " [3, 296, 297, 11],\n",
       " [3, 296, 297, 11, 1],\n",
       " [3, 296, 297, 11, 1, 298],\n",
       " [3, 296, 297, 11, 1, 298, 28],\n",
       " [3, 296, 297, 11, 1, 298, 28, 299],\n",
       " [3, 296, 297, 11, 1, 298, 28, 299, 10],\n",
       " [3, 296, 297, 11, 1, 298, 28, 299, 10, 5],\n",
       " [3, 296, 297, 11, 1, 298, 28, 299, 10, 5, 300],\n",
       " [3, 296, 297, 11, 1, 298, 28, 299, 10, 5, 300, 106],\n",
       " [2, 39],\n",
       " [2, 39, 26],\n",
       " [2, 39, 26, 65],\n",
       " [2, 39, 26, 65, 40],\n",
       " [2, 39, 26, 65, 40, 301],\n",
       " [2, 39, 26, 65, 40, 301, 66],\n",
       " [2, 39, 26, 65, 40, 301, 66, 302],\n",
       " [2, 39, 26, 65, 40, 301, 66, 302, 303],\n",
       " [2, 39, 26, 65, 40, 301, 66, 302, 303, 304],\n",
       " [1, 305],\n",
       " [1, 305, 306],\n",
       " [1, 305, 306, 307],\n",
       " [1, 305, 306, 307, 4],\n",
       " [1, 305, 306, 307, 4, 2],\n",
       " [1, 305, 306, 307, 4, 2, 101],\n",
       " [1, 305, 306, 307, 4, 2, 101, 6],\n",
       " [1, 305, 306, 307, 4, 2, 101, 6, 308],\n",
       " [1, 305, 306, 307, 4, 2, 101, 6, 308, 14],\n",
       " [1, 305, 306, 307, 4, 2, 101, 6, 308, 14, 3],\n",
       " [1, 305, 306, 307, 4, 2, 101, 6, 308, 14, 3, 15],\n",
       " [31, 69],\n",
       " [31, 69, 17],\n",
       " [31, 69, 17, 1],\n",
       " [31, 69, 17, 1, 62],\n",
       " [31, 69, 17, 1, 62, 5],\n",
       " [31, 69, 17, 1, 62, 5, 309],\n",
       " [31, 69, 17, 1, 62, 5, 309, 11],\n",
       " [31, 69, 17, 1, 62, 5, 309, 11, 1],\n",
       " [31, 69, 17, 1, 62, 5, 309, 11, 1, 310],\n",
       " [1, 24],\n",
       " [1, 24, 118],\n",
       " [1, 24, 118, 89],\n",
       " [1, 24, 118, 89, 13],\n",
       " [1, 24, 118, 89, 13, 14],\n",
       " [1, 24, 118, 89, 13, 14, 41],\n",
       " [1, 24, 118, 89, 13, 14, 41, 311],\n",
       " [1, 24, 118, 89, 13, 14, 41, 311, 119],\n",
       " [2, 9],\n",
       " [2, 9, 312],\n",
       " [2, 9, 312, 4],\n",
       " [2, 9, 312, 4, 34],\n",
       " [2, 9, 312, 4, 34, 3],\n",
       " [2, 9, 312, 4, 34, 3, 110],\n",
       " [2, 9, 312, 4, 34, 3, 110, 63],\n",
       " [2, 9, 312, 4, 34, 3, 110, 63, 313],\n",
       " [1, 71],\n",
       " [1, 71, 5],\n",
       " [1, 71, 5, 314],\n",
       " [1, 71, 5, 314, 67],\n",
       " [1, 71, 5, 314, 67, 1],\n",
       " [1, 71, 5, 314, 67, 1, 68],\n",
       " [57, 81],\n",
       " [57, 81, 2],\n",
       " [57, 81, 2, 95],\n",
       " [57, 81, 2, 95, 8],\n",
       " [57, 81, 2, 95, 8, 315],\n",
       " [57, 81, 2, 95, 8, 315, 4],\n",
       " [57, 81, 2, 95, 8, 315, 4, 316],\n",
       " [57, 81, 2, 95, 8, 315, 4, 316, 8],\n",
       " [57, 81, 2, 95, 8, 315, 4, 316, 8, 317],\n",
       " [2, 86],\n",
       " [2, 86, 47],\n",
       " [2, 86, 47, 48],\n",
       " [2, 86, 47, 48, 318],\n",
       " [2, 86, 47, 48, 318, 120],\n",
       " [2, 86, 47, 48, 318, 120, 5],\n",
       " [2, 86, 47, 48, 318, 120, 5, 319],\n",
       " [2, 86, 47, 48, 318, 120, 5, 319, 320],\n",
       " [14, 9],\n",
       " [14, 9, 10],\n",
       " [14, 9, 10, 321],\n",
       " [14, 9, 10, 321, 6],\n",
       " [14, 9, 10, 321, 6, 72],\n",
       " [14, 9, 10, 321, 6, 72, 322],\n",
       " [14, 9, 10, 321, 6, 72, 322, 70],\n",
       " [2, 323],\n",
       " [2, 323, 1],\n",
       " [2, 323, 1, 113],\n",
       " [2, 323, 1, 113, 324],\n",
       " [2, 323, 1, 113, 324, 6],\n",
       " [2, 323, 1, 113, 324, 6, 325],\n",
       " [2, 323, 1, 113, 324, 6, 325, 121],\n",
       " [2, 323, 1, 113, 324, 6, 325, 121, 85],\n",
       " [1, 326],\n",
       " [1, 326, 327],\n",
       " [1, 326, 327, 328],\n",
       " [1, 326, 327, 328, 13],\n",
       " [1, 326, 327, 328, 13, 14],\n",
       " [1, 326, 327, 328, 13, 14, 9],\n",
       " [1, 326, 327, 328, 13, 14, 9, 10],\n",
       " [1, 326, 327, 328, 13, 14, 9, 10, 54],\n",
       " [1, 326, 327, 328, 13, 14, 9, 10, 54, 122],\n",
       " [329, 2],\n",
       " [329, 2, 9],\n",
       " [329, 2, 9, 3],\n",
       " [329, 2, 9, 3, 29],\n",
       " [329, 2, 9, 3, 29, 5],\n",
       " [329, 2, 9, 3, 29, 5, 330],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331, 4],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331, 4, 36],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331, 4, 36, 20],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331, 4, 36, 20, 1],\n",
       " [329, 2, 9, 3, 29, 5, 330, 331, 4, 36, 20, 1, 332],\n",
       " [1, 333],\n",
       " [1, 333, 334],\n",
       " [1, 333, 334, 335],\n",
       " [1, 333, 334, 335, 336],\n",
       " [1, 333, 334, 335, 336, 1],\n",
       " [1, 333, 334, 335, 336, 1, 60],\n",
       " [1, 333, 334, 335, 336, 1, 60, 337],\n",
       " [2, 338],\n",
       " [2, 338, 3],\n",
       " [2, 338, 3, 38],\n",
       " [2, 338, 3, 38, 339],\n",
       " [2, 338, 3, 38, 339, 6],\n",
       " [2, 338, 3, 38, 339, 6, 340],\n",
       " [2, 338, 3, 38, 339, 6, 340, 341],\n",
       " [2, 338, 3, 38, 339, 6, 340, 341, 65],\n",
       " [2, 338, 3, 38, 339, 6, 340, 341, 65, 342],\n",
       " [2, 338, 3, 38, 339, 6, 340, 341, 65, 342, 73],\n",
       " [2, 338, 3, 38, 339, 6, 340, 341, 65, 342, 73, 343],\n",
       " [344, 345],\n",
       " [344, 345, 6],\n",
       " [344, 345, 6, 104],\n",
       " [344, 345, 6, 104, 123],\n",
       " [344, 345, 6, 104, 123, 96],\n",
       " [344, 345, 6, 104, 123, 96, 346],\n",
       " [344, 345, 6, 104, 123, 96, 346, 347],\n",
       " [344, 345, 6, 104, 123, 96, 346, 347, 7],\n",
       " [344, 345, 6, 104, 123, 96, 346, 347, 7, 348],\n",
       " [2, 349],\n",
       " [2, 349, 25],\n",
       " [2, 349, 25, 63],\n",
       " [2, 349, 25, 63, 350],\n",
       " [2, 349, 25, 63, 350, 6],\n",
       " [2, 349, 25, 63, 350, 6, 3],\n",
       " [2, 349, 25, 63, 350, 6, 3, 351],\n",
       " [2, 349, 25, 63, 350, 6, 3, 351, 26],\n",
       " [2, 349, 25, 63, 350, 6, 3, 351, 26, 352],\n",
       " [1, 353],\n",
       " [1, 353, 354],\n",
       " [1, 353, 354, 26],\n",
       " [1, 353, 354, 26, 355],\n",
       " [1, 353, 354, 26, 355, 105],\n",
       " [1, 353, 354, 26, 355, 105, 356],\n",
       " [1, 353, 354, 26, 355, 105, 356, 4],\n",
       " [1, 353, 354, 26, 355, 105, 356, 4, 357],\n",
       " [1, 353, 354, 26, 355, 105, 356, 4, 357, 358],\n",
       " [2, 359],\n",
       " [2, 359, 360],\n",
       " [2, 359, 360, 19],\n",
       " [2, 359, 360, 19, 361],\n",
       " [2, 359, 360, 19, 361, 119],\n",
       " [2, 359, 360, 19, 361, 119, 362],\n",
       " [2, 359, 360, 19, 361, 119, 362, 363],\n",
       " [1, 88],\n",
       " [1, 88, 7],\n",
       " [1, 88, 7, 364],\n",
       " [1, 88, 7, 364, 4],\n",
       " [1, 88, 7, 364, 4, 365],\n",
       " [1, 88, 7, 364, 4, 365, 12],\n",
       " [1, 88, 7, 364, 4, 365, 12, 3],\n",
       " [1, 88, 7, 364, 4, 365, 12, 3, 45],\n",
       " [1, 88, 7, 364, 4, 365, 12, 3, 45, 366],\n",
       " [2, 367],\n",
       " [2, 367, 1],\n",
       " [2, 367, 1, 368],\n",
       " [2, 367, 1, 368, 4],\n",
       " [2, 367, 1, 368, 4, 23],\n",
       " [2, 367, 1, 368, 4, 23, 37],\n",
       " [2, 367, 1, 368, 4, 23, 37, 12],\n",
       " [2, 367, 1, 368, 4, 23, 37, 12, 3],\n",
       " [2, 367, 1, 368, 4, 23, 37, 12, 3, 369],\n",
       " [2, 367, 1, 368, 4, 23, 37, 12, 3, 369, 370],\n",
       " [2, 367, 1, 368, 4, 23, 37, 12, 3, 369, 370, 46],\n",
       " [1, 371],\n",
       " [1, 371, 372],\n",
       " [1, 371, 372, 373],\n",
       " [1, 371, 372, 373, 102],\n",
       " [1, 371, 372, 373, 102, 2],\n",
       " [1, 371, 372, 373, 102, 2, 374],\n",
       " [1, 371, 372, 373, 102, 2, 374, 27],\n",
       " [2, 375],\n",
       " [2, 375, 124],\n",
       " [2, 375, 124, 3],\n",
       " [2, 375, 124, 3, 376],\n",
       " [2, 375, 124, 3, 376, 377],\n",
       " [2, 375, 124, 3, 376, 377, 378],\n",
       " [2, 375, 124, 3, 376, 377, 378, 379],\n",
       " [2, 375, 124, 3, 376, 377, 378, 379, 11],\n",
       " [2, 375, 124, 3, 376, 377, 378, 379, 11, 380],\n",
       " [116, 93],\n",
       " [116, 93, 2],\n",
       " [116, 93, 2, 118],\n",
       " [116, 93, 2, 118, 43],\n",
       " [116, 93, 2, 118, 43, 3],\n",
       " [116, 93, 2, 118, 43, 3, 381],\n",
       " [116, 93, 2, 118, 43, 3, 381, 5],\n",
       " [116, 93, 2, 118, 43, 3, 381, 5, 382],\n",
       " [116, 93, 2, 118, 43, 3, 381, 5, 382, 4],\n",
       " [116, 93, 2, 118, 43, 3, 381, 5, 382, 4, 36],\n",
       " [116, 93, 2, 118, 43, 3, 381, 5, 382, 4, 36, 383],\n",
       " [2, 97],\n",
       " [2, 97, 19],\n",
       " [2, 97, 19, 8],\n",
       " [2, 97, 19, 8, 384],\n",
       " [2, 97, 19, 8, 384, 4],\n",
       " [2, 97, 19, 8, 384, 4, 59],\n",
       " [2, 97, 19, 8, 384, 4, 59, 124],\n",
       " [2, 97, 19, 8, 384, 4, 59, 124, 48],\n",
       " [2, 97, 19, 8, 384, 4, 59, 124, 48, 385],\n",
       " [1, 71],\n",
       " [1, 71, 5],\n",
       " [1, 71, 5, 24],\n",
       " [1, 71, 5, 24, 117],\n",
       " [1, 71, 5, 24, 117, 386],\n",
       " [1, 71, 5, 24, 117, 386, 11],\n",
       " [1, 71, 5, 24, 117, 386, 11, 1],\n",
       " [1, 71, 5, 24, 117, 386, 11, 1, 74],\n",
       " [2, 53],\n",
       " [2, 53, 112],\n",
       " [2, 53, 112, 1],\n",
       " [2, 53, 112, 1, 387],\n",
       " [2, 53, 112, 1, 387, 4],\n",
       " [2, 53, 112, 1, 387, 4, 34],\n",
       " [2, 53, 112, 1, 387, 4, 34, 1],\n",
       " [2, 53, 112, 1, 387, 4, 34, 1, 388],\n",
       " [2, 53, 112, 1, 387, 4, 34, 1, 388, 389],\n",
       " [2, 53, 112, 1, 387, 4, 34, 1, 388, 389, 390],\n",
       " [14, 41],\n",
       " [14, 41, 115],\n",
       " [14, 41, 115, 6],\n",
       " [14, 41, 115, 6, 391],\n",
       " [14, 41, 115, 6, 391, 1],\n",
       " [14, 41, 115, 6, 391, 1, 15],\n",
       " [14, 41, 115, 6, 391, 1, 15, 100],\n",
       " [14, 41, 115, 6, 391, 1, 15, 100, 392],\n",
       " [14, 41, 115, 6, 391, 1, 15, 100, 392, 393],\n",
       " [394, 69],\n",
       " [394, 69, 395],\n",
       " [394, 69, 395, 13],\n",
       " [394, 69, 395, 13, 396],\n",
       " [394, 69, 395, 13, 396, 76],\n",
       " [394, 69, 395, 13, 396, 76, 90],\n",
       " [31, 84],\n",
       " [31, 84, 397],\n",
       " [31, 84, 397, 1],\n",
       " [31, 84, 397, 1, 398],\n",
       " [31, 84, 397, 1, 398, 4],\n",
       " [31, 84, 397, 1, 398, 4, 42],\n",
       " [31, 84, 397, 1, 398, 4, 42, 10],\n",
       " [31, 84, 397, 1, 398, 4, 42, 10, 18],\n",
       " [31, 84, 397, 1, 398, 4, 42, 10, 18, 399],\n",
       " [2, 400],\n",
       " [2, 400, 4],\n",
       " [2, 400, 4, 44],\n",
       " [2, 400, 4, 44, 3],\n",
       " [2, 400, 4, 44, 3, 401],\n",
       " [2, 400, 4, 44, 3, 401, 402],\n",
       " [2, 400, 4, 44, 3, 401, 402, 16],\n",
       " [2, 400, 4, 44, 3, 401, 402, 16, 403],\n",
       " [2, 400, 4, 44, 3, 401, 402, 16, 403, 37],\n",
       " [2, 400, 4, 44, 3, 401, 402, 16, 403, 37, 5],\n",
       " [2, 400, 4, 44, 3, 401, 402, 16, 403, 37, 5, 64],\n",
       " [1, 404],\n",
       " [1, 404, 51],\n",
       " [1, 404, 51, 41],\n",
       " [1, 404, 51, 41, 122],\n",
       " [1, 404, 51, 41, 122, 4],\n",
       " [1, 404, 51, 41, 122, 4, 120],\n",
       " [1, 404, 51, 41, 122, 4, 120, 5],\n",
       " [1, 404, 51, 41, 122, 4, 120, 5, 405],\n",
       " [2, 9],\n",
       " [2, 9, 8],\n",
       " [2, 9, 8, 30],\n",
       " [2, 9, 8, 30, 4],\n",
       " [2, 9, 8, 30, 4, 39],\n",
       " [2, 9, 8, 30, 4, 39, 26],\n",
       " [2, 9, 8, 30, 4, 39, 26, 406],\n",
       " [2, 9, 8, 30, 4, 39, 26, 406, 6],\n",
       " [2, 9, 8, 30, 4, 39, 26, 406, 6, 407],\n",
       " [2, 9, 8, 30, 4, 39, 26, 406, 6, 407, 123],\n",
       " [408, 33],\n",
       " [408, 33, 409],\n",
       " [408, 33, 409, 410],\n",
       " [408, 33, 409, 410, 121],\n",
       " [408, 33, 409, 410, 121, 411],\n",
       " [408, 33, 409, 410, 121, 411, 4],\n",
       " [408, 33, 409, 410, 121, 411, 4, 92]]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d6afa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding to make sure lists are of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "62bf7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the length of the longest sequence in input_sequences\n",
    "# [len(x) for x in input_sequences] creates a list of lengths of all sequences\n",
    "# max(...) then returns the maximum length among them\n",
    "# This is useful for padding all sequences to the same length before feeding into the LSTM\n",
    "max_length=max([len(x) for x in input_sequences]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "064a40af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   2,  42],\n",
       "       [  0,   0,   0, ...,   2,  42,  18],\n",
       "       [  0,   0,   0, ...,  42,  18, 125],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 410, 121, 411],\n",
       "       [  0,   0,   0, ..., 121, 411,   4],\n",
       "       [  0,   0,   0, ..., 411,   4,  92]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences=pad_sequences(input_sequences,maxlen=max_length,padding='pre')\n",
    "\n",
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5919850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   2],\n",
       "       [  0,   0,   0, ...,   0,   2,  42],\n",
       "       [  0,   0,   0, ...,   2,  42,  18],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 409, 410, 121],\n",
       "       [  0,   0,   0, ..., 410, 121, 411],\n",
       "       [  0,   0,   0, ..., 121, 411,   4]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "X=padded_input_sequences[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8fff3194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  18, 125,   4,   9,  43,   3,  29,   5,  30, 126,   7, 127,\n",
       "        19,   1,  75,  76,  31,  44,   3,  45,  46,  16, 128,   8, 129,\n",
       "        77, 130,  17,   3,  78,  79,  47,  48,  80,  82,  83,  32,  49,\n",
       "        33, 131,   1, 132,   4,  34,   1, 133, 134,  11,   1,  84,   7,\n",
       "         3, 135, 136,  51,   8,  52,  53,  20,  21, 137,   6, 138,   1,\n",
       "        31,  54, 139, 140, 141,  20,   1, 142, 143,  12, 144,  35,   8,\n",
       "       145,  16,   1,  15,  22,  55, 146,   7,  85,  13, 147, 148, 149,\n",
       "         3, 150, 151,   2,  86, 152,  87,  88,  56,   2,  36,  89,  17,\n",
       "         3,  29,   5, 153,   4,   3, 154, 155, 156,  10,  11, 157,   2,\n",
       "       158, 159,   5,  90,  23,  37,   6, 160, 161,   4, 162, 163,   3,\n",
       "       164, 165,   7, 166,  32,  49,  33, 167,  18,  21,  58, 168,   4,\n",
       "         3, 169,   5, 170, 171,  59,   4,  91,  10,   3,  92,  60,   2,\n",
       "        22,  93,  14, 172,   6,  24,  94, 173,   1,  52,   4, 174,   6,\n",
       "         1,  62,   5,   1,  24,   7, 175,   4, 176,  57,   3, 177,  15,\n",
       "        95,   1, 178,  63, 179,   3, 180, 181,  64,   2, 182,   3,  38,\n",
       "       183,  11,   8, 184,  39,  26,  65, 185,   1,  96,  66, 186,  27,\n",
       "       187,  67,   8,  68,  19,   1, 188,  75,  97,  19, 189, 190,  12,\n",
       "         3,  38, 191,  16,  98,  69,   4,  23, 100, 192,  40, 193,  42,\n",
       "        18,  70,   6,   1,  62,   5, 194,  51,  71,   5,  58,  30,   9,\n",
       "        10, 195, 101,   6,  72,   8,  15,  17,  21, 196, 197,  41, 198,\n",
       "       199,   8, 200, 102,   2, 201, 202,  35,   1, 103,  13, 203,  22,\n",
       "       204,   5,  14,  80, 205,   6, 206,  21, 207, 103, 208, 209,   4,\n",
       "       210,   6, 104, 211,  33,   7, 212,  79,  87, 213,  25, 214,  20,\n",
       "         3, 105, 215,  28,  66, 216, 217,  12, 106, 218, 219,   7, 220,\n",
       "        32,  49,   9,   3, 221,   5, 222,   2, 223, 224,  11, 225,  60,\n",
       "       107,  53, 226,   5, 227,   4, 228,  44,   3,  38, 229,   6, 230,\n",
       "         1, 231,   7, 232, 108,   2, 109,  54, 233, 234,  40,  34,   3,\n",
       "        45, 110,  16, 235,   6,  64,  99,  73,  67,  17, 236,  13, 111,\n",
       "       237, 238,  23, 112,  13,   2, 239, 240, 241, 242,  22,  18,  61,\n",
       "         1,  68,   7, 243, 244,  35,   8, 245,  12,   1,  15,   4, 246,\n",
       "        73,  55, 247, 248,  13, 249, 250, 251, 252, 253,  29,   5,  30,\n",
       "         4, 254,  43,   6,  72, 255, 256,  23,  83,  32,   2, 257,   9,\n",
       "         3, 259,  28, 260,   1, 261, 262, 113,   2,   7, 263,   3, 264,\n",
       "       265,  37,  12,   3,  46,   6, 266,  21,  58,  74,  74, 267,   5,\n",
       "        24, 268, 269,   1, 107,   7, 270, 271,   3, 272,  28, 273, 274,\n",
       "       275,   4, 276,  10,  12,   3, 114,  59,   4,  91,   1, 277,   3,\n",
       "       115,  15,   2,  22, 116,   2,  35,   8,  77,  70,   7,   3,  78,\n",
       "       278,  10,   5,  47, 279, 280, 281, 282,  28, 283,   7,   1, 284,\n",
       "        39,   5,  98,  11,   9,  10, 111,   7, 285,  17,   3, 114,  55,\n",
       "        40, 286, 109, 287, 108,  14, 117,  82, 288,  36,  27,   1,  52,\n",
       "       289, 290, 291,  27, 292, 293,  94,  20,   1, 294, 295, 296, 297,\n",
       "        11,   1, 298,  28, 299,  10,   5, 300, 106,  39,  26,  65,  40,\n",
       "       301,  66, 302, 303, 304, 305, 306, 307,   4,   2, 101,   6, 308,\n",
       "        14,   3,  15,  69,  17,   1,  62,   5, 309,  11,   1, 310,  24,\n",
       "       118,  89,  13,  14,  41, 311, 119,   9, 312,   4,  34,   3, 110,\n",
       "        63, 313,  71,   5, 314,  67,   1,  68,  81,   2,  95,   8, 315,\n",
       "         4, 316,   8, 317,  86,  47,  48, 318, 120,   5, 319, 320,   9,\n",
       "        10, 321,   6,  72, 322,  70, 323,   1, 113, 324,   6, 325, 121,\n",
       "        85, 326, 327, 328,  13,  14,   9,  10,  54, 122,   2,   9,   3,\n",
       "        29,   5, 330, 331,   4,  36,  20,   1, 332, 333, 334, 335, 336,\n",
       "         1,  60, 337, 338,   3,  38, 339,   6, 340, 341,  65, 342,  73,\n",
       "       343, 345,   6, 104, 123,  96, 346, 347,   7, 348, 349,  25,  63,\n",
       "       350,   6,   3, 351,  26, 352, 353, 354,  26, 355, 105, 356,   4,\n",
       "       357, 358, 359, 360,  19, 361, 119, 362, 363,  88,   7, 364,   4,\n",
       "       365,  12,   3,  45, 366, 367,   1, 368,   4,  23,  37,  12,   3,\n",
       "       369, 370,  46, 371, 372, 373, 102,   2, 374,  27, 375, 124,   3,\n",
       "       376, 377, 378, 379,  11, 380,  93,   2, 118,  43,   3, 381,   5,\n",
       "       382,   4,  36, 383,  97,  19,   8, 384,   4,  59, 124,  48, 385,\n",
       "        71,   5,  24, 117, 386,  11,   1,  74,  53, 112,   1, 387,   4,\n",
       "        34,   1, 388, 389, 390,  41, 115,   6, 391,   1,  15, 100, 392,\n",
       "       393,  69, 395,  13, 396,  76,  90,  84, 397,   1, 398,   4,  42,\n",
       "        10,  18, 399, 400,   4,  44,   3, 401, 402,  16, 403,  37,   5,\n",
       "        64, 404,  51,  41, 122,   4, 120,   5, 405,   9,   8,  30,   4,\n",
       "        39,  26, 406,   6, 407, 123,  33, 409, 410, 121, 411,   4,  92])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output\n",
    "y=padded_input_sequences[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b28eb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Till this point we've converted a text-generation task into a supervised machine learning task, this is a multiclass-classification task as, the output is discrete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f44b85a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 13)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a8203947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8fb65cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d14715f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the output (y)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=412) # num_classes = number of unique words in the vocabulary, we wrote 412 instead of 411 as tokenizer.word_index states from 1 and one hot encoding starts from 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b790ba43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(832, 412)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "46f257bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3e283ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c61cec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(412,100,input_shape=(14,)))\n",
    "model.add(LSTM(250)) # number of nodes in each gate\n",
    "model.add(Dense(412,activation='softmax')) # output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7cbe585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a974ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">351,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">103,412</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m41,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │       \u001b[38;5;34m351,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m412\u001b[0m)            │       \u001b[38;5;34m103,412\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,612</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m495,612\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">495,612</span> (1.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m495,612\u001b[0m (1.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1f34e767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.0270 - loss: 5.9642\n",
      "Epoch 2/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0464 - loss: 5.5474\n",
      "Epoch 3/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0481 - loss: 5.4878\n",
      "Epoch 4/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0444 - loss: 5.4661\n",
      "Epoch 5/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0526 - loss: 5.3871\n",
      "Epoch 6/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0501 - loss: 5.3120\n",
      "Epoch 7/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0545 - loss: 5.1690\n",
      "Epoch 8/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0566 - loss: 4.9355\n",
      "Epoch 9/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0848 - loss: 4.8319\n",
      "Epoch 10/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0987 - loss: 4.6385\n",
      "Epoch 11/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1251 - loss: 4.3818\n",
      "Epoch 12/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1369 - loss: 4.0153\n",
      "Epoch 13/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1889 - loss: 3.7509\n",
      "Epoch 14/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2370 - loss: 3.4698\n",
      "Epoch 15/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2872 - loss: 3.1455\n",
      "Epoch 16/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3615 - loss: 2.8931\n",
      "Epoch 17/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4443 - loss: 2.6486\n",
      "Epoch 18/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4855 - loss: 2.4290\n",
      "Epoch 19/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5923 - loss: 2.1747\n",
      "Epoch 20/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6262 - loss: 1.9477\n",
      "Epoch 21/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7045 - loss: 1.7004\n",
      "Epoch 22/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7334 - loss: 1.5798\n",
      "Epoch 23/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7784 - loss: 1.4089\n",
      "Epoch 24/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7972 - loss: 1.2848\n",
      "Epoch 25/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8012 - loss: 1.2016\n",
      "Epoch 26/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8391 - loss: 1.0812\n",
      "Epoch 27/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8434 - loss: 0.9841\n",
      "Epoch 28/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8336 - loss: 0.9584\n",
      "Epoch 29/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8407 - loss: 0.9172\n",
      "Epoch 30/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8531 - loss: 0.8726\n",
      "Epoch 31/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8705 - loss: 0.7452\n",
      "Epoch 32/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8697 - loss: 0.7190\n",
      "Epoch 33/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.7399\n",
      "Epoch 34/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8712 - loss: 0.6862\n",
      "Epoch 35/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8730 - loss: 0.6641\n",
      "Epoch 36/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8806 - loss: 0.6119\n",
      "Epoch 37/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8835 - loss: 0.5761\n",
      "Epoch 38/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8833 - loss: 0.5740\n",
      "Epoch 39/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8982 - loss: 0.5315\n",
      "Epoch 40/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8903 - loss: 0.5237\n",
      "Epoch 41/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9088 - loss: 0.4363\n",
      "Epoch 42/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9054 - loss: 0.4588\n",
      "Epoch 43/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9021 - loss: 0.4908\n",
      "Epoch 44/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8983 - loss: 0.4387\n",
      "Epoch 45/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8826 - loss: 0.4677\n",
      "Epoch 46/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8965 - loss: 0.4453\n",
      "Epoch 47/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8766 - loss: 0.5107\n",
      "Epoch 48/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8701 - loss: 0.4952\n",
      "Epoch 49/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8916 - loss: 0.4514\n",
      "Epoch 50/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9039 - loss: 0.3944\n",
      "Epoch 51/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8885 - loss: 0.4254\n",
      "Epoch 52/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8961 - loss: 0.3975\n",
      "Epoch 53/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9003 - loss: 0.3847\n",
      "Epoch 54/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9036 - loss: 0.3790\n",
      "Epoch 55/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8960 - loss: 0.3862\n",
      "Epoch 56/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8950 - loss: 0.3898\n",
      "Epoch 57/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8997 - loss: 0.3754\n",
      "Epoch 58/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8939 - loss: 0.3604\n",
      "Epoch 59/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9051 - loss: 0.3621\n",
      "Epoch 60/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8873 - loss: 0.3941\n",
      "Epoch 61/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8820 - loss: 0.3714\n",
      "Epoch 62/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8859 - loss: 0.4139\n",
      "Epoch 63/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9009 - loss: 0.3574\n",
      "Epoch 64/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9097 - loss: 0.3432\n",
      "Epoch 65/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8950 - loss: 0.3558\n",
      "Epoch 66/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8808 - loss: 0.3830\n",
      "Epoch 67/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8848 - loss: 0.3799\n",
      "Epoch 68/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9058 - loss: 0.3282\n",
      "Epoch 69/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8939 - loss: 0.3419\n",
      "Epoch 70/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8874 - loss: 0.3890\n",
      "Epoch 71/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8957 - loss: 0.3489\n",
      "Epoch 72/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8754 - loss: 0.4082\n",
      "Epoch 73/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8719 - loss: 0.4038\n",
      "Epoch 74/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9032 - loss: 0.3305\n",
      "Epoch 75/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.3408\n",
      "Epoch 76/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8916 - loss: 0.3434\n",
      "Epoch 77/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9036 - loss: 0.3301\n",
      "Epoch 78/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8958 - loss: 0.3637\n",
      "Epoch 79/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8928 - loss: 0.3693\n",
      "Epoch 80/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9168 - loss: 0.3159\n",
      "Epoch 81/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8859 - loss: 0.3846\n",
      "Epoch 82/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8933 - loss: 0.3416\n",
      "Epoch 83/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8995 - loss: 0.3310\n",
      "Epoch 84/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8912 - loss: 0.3300\n",
      "Epoch 85/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8971 - loss: 0.3237\n",
      "Epoch 86/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2865\n",
      "Epoch 87/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9016 - loss: 0.3367\n",
      "Epoch 88/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8996 - loss: 0.3133\n",
      "Epoch 89/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9093 - loss: 0.3247\n",
      "Epoch 90/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8994 - loss: 0.3487\n",
      "Epoch 91/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9030 - loss: 0.3269\n",
      "Epoch 92/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8941 - loss: 0.3268\n",
      "Epoch 93/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8962 - loss: 0.3293\n",
      "Epoch 94/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8979 - loss: 0.3405\n",
      "Epoch 95/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9034 - loss: 0.2835\n",
      "Epoch 96/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 0.3063\n",
      "Epoch 97/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8843 - loss: 0.3440\n",
      "Epoch 98/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8724 - loss: 0.4099\n",
      "Epoch 99/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8931 - loss: 0.3394\n",
      "Epoch 100/100\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8990 - loss: 0.3425\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c27e2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.30236116e-07, 1.94781114e-05, 2.87418770e-05, 6.10568037e-04,\n",
       "        1.10330766e-05, 3.01280238e-06, 2.87192757e-03, 7.18062336e-04,\n",
       "        1.26961662e-04, 3.99853662e-02, 1.67768088e-03, 1.47898379e-06,\n",
       "        9.12298929e-05, 4.39270843e-06, 3.87156506e-05, 3.00085071e-06,\n",
       "        4.74098761e-06, 5.41814115e-05, 1.15027389e-04, 2.63093767e-04,\n",
       "        8.62366142e-05, 5.35195431e-05, 3.11005657e-04, 1.45082397e-03,\n",
       "        3.07388778e-04, 3.32047464e-04, 7.11660177e-05, 2.07065095e-04,\n",
       "        6.26411065e-06, 1.44627556e-04, 3.01905402e-05, 9.28842042e-07,\n",
       "        2.28660909e-04, 3.99072887e-03, 5.93900797e-04, 6.95549184e-04,\n",
       "        1.84966205e-03, 1.62880030e-03, 6.70563750e-05, 2.24015536e-03,\n",
       "        1.09271268e-05, 1.74064673e-02, 2.68578087e-03, 7.63345161e-04,\n",
       "        3.71029601e-03, 1.61951630e-05, 1.53940389e-04, 1.76905043e-04,\n",
       "        3.98029661e-05, 9.43179548e-05, 4.07851246e-07, 1.12128990e-04,\n",
       "        8.16466354e-07, 2.49532494e-03, 9.23735352e-05, 1.36428251e-04,\n",
       "        5.20468038e-03, 4.98468471e-05, 8.02687500e-05, 1.42608653e-03,\n",
       "        6.34426760e-05, 3.09258729e-04, 1.66303181e-07, 1.65331312e-05,\n",
       "        1.10671418e-02, 5.92041397e-05, 7.42452812e-06, 4.34565518e-05,\n",
       "        7.15471879e-06, 1.19635407e-02, 5.65337134e-04, 2.79600848e-04,\n",
       "        5.38760651e-05, 2.78670457e-03, 7.97950051e-05, 6.54121834e-07,\n",
       "        1.14596160e-05, 4.20773635e-03, 7.89774822e-06, 7.03069309e-05,\n",
       "        6.70637295e-04, 5.28745912e-03, 3.62170907e-03, 2.15970492e-03,\n",
       "        6.75185909e-03, 4.66219475e-03, 4.96715598e-04, 9.62513786e-06,\n",
       "        1.33763213e-04, 8.29021737e-05, 5.34701348e-06, 3.54230433e-05,\n",
       "        2.55908367e-06, 6.61199680e-04, 2.60347315e-05, 1.28346868e-03,\n",
       "        1.22000745e-06, 5.69936261e-03, 3.89492425e-06, 3.53515986e-03,\n",
       "        3.43765016e-04, 1.97027647e-03, 3.08760864e-05, 7.03214828e-05,\n",
       "        1.65202709e-05, 3.33904654e-06, 6.29329297e-05, 9.52672053e-06,\n",
       "        1.51836881e-04, 9.12329764e-04, 7.38306699e-06, 5.51012636e-06,\n",
       "        4.74158267e-04, 2.85430811e-04, 2.16893136e-06, 2.74832291e-03,\n",
       "        1.04273895e-04, 2.36137166e-05, 6.93234178e-05, 5.48650642e-05,\n",
       "        3.68321821e-06, 2.78285588e-05, 3.12981356e-05, 1.13851174e-05,\n",
       "        1.35919114e-03, 2.27277545e-04, 1.22198951e-04, 1.24941114e-04,\n",
       "        4.72193688e-06, 2.32132265e-06, 4.51813714e-04, 1.67073240e-03,\n",
       "        1.10341352e-06, 8.29175065e-07, 1.23427508e-05, 2.38611683e-05,\n",
       "        7.23023231e-06, 7.91623336e-07, 2.80689665e-06, 1.09325640e-06,\n",
       "        6.74589246e-05, 3.37947095e-05, 1.67449826e-07, 5.32004469e-06,\n",
       "        3.79651078e-06, 2.49203222e-05, 1.49756333e-05, 9.70248857e-06,\n",
       "        1.34010324e-05, 2.00067693e-03, 8.39848944e-05, 1.09372713e-05,\n",
       "        1.49610869e-05, 3.50986534e-06, 5.59572936e-06, 9.60923935e-05,\n",
       "        3.97037511e-05, 6.71594098e-05, 1.95211232e-05, 4.94414453e-05,\n",
       "        4.08311644e-05, 4.74132230e-06, 9.89545697e-06, 9.04920598e-05,\n",
       "        1.60545187e-05, 1.05714542e-04, 5.97977138e-04, 3.25780408e-03,\n",
       "        6.25801476e-06, 1.13518108e-05, 7.32390663e-06, 7.71147534e-05,\n",
       "        8.01756396e-05, 1.64760405e-03, 3.73262833e-06, 3.51772207e-04,\n",
       "        1.20116356e-05, 4.04565035e-05, 1.08447966e-06, 5.77127594e-06,\n",
       "        1.85839906e-06, 7.70720817e-06, 4.02288133e-05, 7.19751279e-06,\n",
       "        6.75881347e-06, 1.13173392e-05, 5.79238076e-07, 9.97456664e-05,\n",
       "        7.14917803e-07, 1.76449437e-04, 3.08286872e-05, 1.09793245e-05,\n",
       "        4.63225660e-05, 3.77259948e-06, 6.62257321e-07, 6.77867938e-05,\n",
       "        1.01017004e-05, 1.16532792e-04, 4.15144859e-05, 3.06568609e-06,\n",
       "        1.30009958e-05, 8.65138463e-06, 2.03837044e-05, 9.14148700e-07,\n",
       "        2.99366038e-05, 2.62452988e-04, 5.71920327e-06, 4.56072075e-06,\n",
       "        2.45896028e-03, 2.98279716e-04, 1.13649612e-05, 6.83261078e-06,\n",
       "        4.91671708e-05, 3.32502327e-06, 1.38229085e-03, 1.02807962e-06,\n",
       "        1.04060109e-06, 4.21715595e-06, 1.10180030e-04, 5.34075771e-05,\n",
       "        3.59516009e-04, 5.91289518e-06, 9.03772559e-07, 2.06479831e-06,\n",
       "        3.16085971e-05, 4.78047150e-05, 1.05360004e-05, 6.14180408e-06,\n",
       "        4.66999700e-06, 9.18714068e-06, 4.13385948e-07, 3.04162683e-07,\n",
       "        1.99435133e-04, 2.58370583e-05, 2.78920088e-05, 4.27723990e-06,\n",
       "        2.09095615e-05, 4.10120720e-06, 1.74378438e-04, 2.09396349e-05,\n",
       "        2.94231922e-05, 2.94062502e-05, 8.91196541e-04, 1.91329855e-05,\n",
       "        4.32571251e-05, 2.47116805e-05, 3.98655993e-06, 2.05088232e-04,\n",
       "        2.11221904e-05, 4.61029776e-06, 1.56960814e-05, 2.55896794e-05,\n",
       "        2.42272695e-03, 3.23059940e-04, 4.50961379e-05, 1.95959306e-04,\n",
       "        2.00295417e-05, 5.90234013e-05, 5.87001750e-07, 6.87822248e-05,\n",
       "        3.72959312e-06, 3.72727300e-07, 7.11004350e-06, 1.45606697e-04,\n",
       "        5.20722210e-07, 1.85106031e-03, 3.60165950e-06, 1.29540767e-05,\n",
       "        6.11782434e-06, 2.83973259e-05, 9.88474221e-06, 1.69360684e-03,\n",
       "        1.04190131e-05, 2.07399285e-06, 1.58378152e-05, 8.55437793e-06,\n",
       "        4.63337419e-05, 4.51611459e-06, 6.74770399e-06, 1.46767234e-05,\n",
       "        8.32174010e-06, 1.37613644e-03, 6.80995654e-05, 2.57796601e-05,\n",
       "        9.11108543e-07, 2.32329374e-04, 3.19041237e-06, 4.82893200e-04,\n",
       "        2.04670378e-05, 2.02509341e-06, 1.50534925e-06, 2.60808156e-06,\n",
       "        9.87527819e-05, 7.48159291e-05, 9.91052730e-07, 3.16244632e-06,\n",
       "        9.85855353e-04, 1.52747452e-05, 1.41268902e-06, 8.01018632e-06,\n",
       "        2.31051235e-05, 5.43485157e-07, 6.61052752e-07, 7.65408095e-06,\n",
       "        3.02757803e-06, 8.57605191e-05, 6.18893973e-05, 7.69546750e-05,\n",
       "        5.50044206e-05, 2.00212480e-06, 1.83751024e-06, 8.17126929e-05,\n",
       "        1.28434491e-04, 5.64085985e-06, 7.36264483e-05, 3.10172300e-06,\n",
       "        9.00099440e-06, 5.30175612e-06, 3.28061788e-06, 1.27887506e-06,\n",
       "        3.44553519e-06, 5.85245471e-05, 1.21185330e-04, 1.09558704e-03,\n",
       "        1.76182857e-05, 8.85194459e-06, 1.38525036e-04, 1.07161912e-04,\n",
       "        4.46380036e-05, 5.76641526e-07, 3.57103818e-06, 4.49322579e-06,\n",
       "        2.43807835e-06, 9.82375714e-05, 1.46145074e-04, 2.95686496e-05,\n",
       "        4.74928056e-05, 4.09820859e-06, 1.61970931e-03, 1.91769923e-05,\n",
       "        2.92550453e-06, 1.04413248e-05, 2.33748597e-06, 7.82472762e-06,\n",
       "        1.09394682e-06, 7.82019615e-01, 8.21897174e-06, 1.05835634e-05,\n",
       "        1.02934946e-05, 2.58125272e-03, 2.08277252e-05, 2.84766384e-06,\n",
       "        1.41771500e-06, 1.18893091e-04, 1.79430775e-04, 1.25047964e-05,\n",
       "        2.17699881e-06, 1.37499119e-05, 4.39669566e-05, 9.00316518e-04,\n",
       "        2.19520158e-03, 4.49139407e-05, 1.14136647e-05, 1.11198115e-05,\n",
       "        7.33333945e-05, 1.28185147e-05, 2.45968495e-05, 1.91143295e-03,\n",
       "        1.83001575e-05, 2.04008193e-05, 6.66237538e-05, 1.00593774e-04,\n",
       "        2.64212267e-05, 1.05339514e-05, 3.27279522e-05, 2.26737116e-03,\n",
       "        2.20976176e-06, 3.09794495e-06, 5.68391158e-07, 6.91433161e-06,\n",
       "        8.59027477e-06, 1.64069002e-06, 1.44866772e-06, 3.38459613e-05,\n",
       "        1.10935316e-05, 3.68126784e-05, 5.38023342e-05, 1.03341264e-07,\n",
       "        1.37719269e-06, 2.92418936e-05, 8.83495977e-06, 8.30188401e-06,\n",
       "        4.72107928e-07, 2.06059740e-05, 7.66338928e-07, 9.54986681e-05,\n",
       "        6.19156890e-06, 2.64682138e-04, 5.49659580e-06, 5.14053718e-05,\n",
       "        1.24283030e-03, 1.89252169e-05, 3.23658569e-05, 3.84009445e-06,\n",
       "        9.62379418e-05, 9.74868499e-07, 1.26381010e-05, 8.24458766e-06,\n",
       "        5.74974933e-07, 6.51911105e-05, 9.22374384e-05, 1.38315454e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction \n",
    "text=\"friend\"\n",
    "\n",
    "# tokenize\n",
    "tokenized=tokenizer.texts_to_sequences([text])[0]\n",
    "# pad\n",
    "padded=pad_sequences([tokenized],maxlen=14,padding='pre')\n",
    "# predict\n",
    "model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29cbf9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(model.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "833c8025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'planned'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "edac725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend planned\n",
      "friend planned to\n",
      "friend planned to meet\n",
      "friend planned to meet next\n",
      "friend planned to meet next week\n"
     ]
    }
   ],
   "source": [
    "text='friend'\n",
    "\n",
    "for i in range(5):\n",
    "    token_text=tokenizer.texts_to_sequences([text])[0]\n",
    "    padded=pad_sequences([token_text],maxlen=14,padding='pre')\n",
    "\n",
    "    probabilities=model.predict(padded, verbose=0)\n",
    "\n",
    "    most_probable_word=np.argmax(probabilities)\n",
    "\n",
    "    next_word=tokenizer.index_word[most_probable_word]\n",
    "\n",
    "    text=text + ' ' + next_word\n",
    "    print(text)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91686d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE ON num_classes (+1 in to_categorical)\n",
    "# ------------------------------------------------------------\n",
    "# The core idea:\n",
    "# The padding index 0 is implicit in the Tokenizer — it exists but is not visible\n",
    "# in tokenizer.word_index. Tokenizer starts assigning indices from 1 onward.\n",
    "#\n",
    "# In one-hot encoding, we leave the 0th index for padding and start normally\n",
    "# from the first index (1). But since we have to leave one position for\n",
    "# the 0-padding or 0th index, we need to add one extra index position.\n",
    "#\n",
    "# So, if tokenizer.word_index gives 411 unique words (indices 1–411),\n",
    "# we actually have 412 possible indices (0–411).\n",
    "#\n",
    "# Therefore:\n",
    "#     num_classes = vocab_size + 1   # 411 + 1 = 412\n",
    "#     y = to_categorical(y, num_classes=412)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
